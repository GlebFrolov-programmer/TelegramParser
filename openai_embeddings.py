import numpy as np
import json
import os
from datetime import datetime
from typing import List, Dict, Any, Tuple
import asyncio

# –ò–º–ø–æ—Ä—Ç—ã –¥–ª—è OpenAI
from openai import AsyncOpenAI
from tenacity import retry, stop_after_attempt, wait_exponential
from dotenv import load_dotenv

# –ò–º–ø–æ—Ä—Ç –¥–ª—è –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞
from sklearn.metrics.pairwise import cosine_similarity


class OpenAIEmbedder:
    """–ö–ª–∞—Å—Å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ —á–µ—Ä–µ–∑ OpenAI API –∏ —Ä–∞–±–æ—Ç—ã —Å –Ω–∏–º–∏"""

    def __init__(self, api_key: str = None, model: str = "text-embedding-3-small"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —ç–º–±–µ–¥–¥–µ—Ä–∞

        Args:
            api_key: –ö–ª—é—á OpenAI API. –ï—Å–ª–∏ None, –±–µ—Ä–µ—Ç—Å—è –∏–∑ .env
            model: –ú–æ–¥–µ–ª—å –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤
        """
        load_dotenv()
        self.api_key = api_key or os.getenv('OPENAI_API_KEY')
        self.model = model
        self.client = None

        if not self.api_key:
            raise ValueError("–ù–µ —É–∫–∞–∑–∞–Ω OPENAI_API_KEY –≤ .env –∏–ª–∏ –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏")

    async def _get_client(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–≥–æ –∫–ª–∏–µ–Ω—Ç–∞ OpenAI"""
        if self.client is None:
            self.client = AsyncOpenAI(api_key=self.api_key)
        return self.client

    @retry(
        stop=stop_after_attempt(3),
        wait=wait_exponential(multiplier=1, min=2, max=10)
    )
    async def get_embedding(self, text: str) -> List[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞ –¥–ª—è –æ–¥–Ω–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
        client = await self._get_client()

        try:
            response = await client.embeddings.create(
                model=self.model,
                input=text,
                encoding_format="float"
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–ª—É—á–µ–Ω–∏–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞: {e}")
            raise

    async def embed_query(self, query: str) -> Dict[str, Any]:
        """
        –í–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict: –°–ª–æ–≤–∞—Ä—å —Å —Ç–µ–∫—Å—Ç–æ–º –∑–∞–ø—Ä–æ—Å–∞ –∏ –µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–º
        """
        try:
            embedding = await self.get_embedding(query)
            return {
                'query_text': query,
                'query_embedding': embedding,
                'timestamp': datetime.now().isoformat()
            }
        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞: {e}")
            return {
                'query_text': query,
                'query_embedding': None,
                'error': str(e),
                'timestamp': datetime.now().isoformat()
            }

    def embed_query_sync(self, query: str) -> Dict[str, Any]:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –≤–µ–∫—Ç–æ—Ä–∏–∑–∞—Ü–∏–∏ –∑–∞–ø—Ä–æ—Å–∞

        Args:
            query: –¢–µ–∫—Å—Ç –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            Dict: –°–ª–æ–≤–∞—Ä—å —Å —Ç–µ–∫—Å—Ç–æ–º –∑–∞–ø—Ä–æ—Å–∞ –∏ –µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–º
        """
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                import nest_asyncio
                nest_asyncio.apply()
                return loop.run_until_complete(self.embed_query(query))
        except RuntimeError:
            pass

        return asyncio.run(self.embed_query(query))

    def calculate_cosine_similarity(self,
                                    query_embedding: List[float],
                                    post_embeddings: List[List[float]]) -> List[float]:
        """
        –†–∞—Å—á–µ—Ç –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ –º–µ–∂–¥—É –≤–µ–∫—Ç–æ—Ä–æ–º –∑–∞–ø—Ä–æ—Å–∞ –∏ –≤–µ–∫—Ç–æ—Ä–∞–º–∏ —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            query_embedding: –í–µ–∫—Ç–æ—Ä –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            post_embeddings: –°–ø–∏—Å–æ–∫ –≤–µ–∫—Ç–æ—Ä–æ–≤ —Å–æ–æ–±—â–µ–Ω–∏–π

        Returns:
            List[float]: –°–ø–∏—Å–æ–∫ –∑–Ω–∞—á–µ–Ω–∏–π –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ —Å—Ö–æ–¥—Å—Ç–≤–∞ (–≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö)
        """
        if not query_embedding or not post_embeddings:
            return []

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ numpy –º–∞—Å—Å–∏–≤—ã
        query_array = np.array(query_embedding).reshape(1, -1)
        posts_array = np.array(post_embeddings)

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = cosine_similarity(query_array, posts_array)[0]

        # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        similarities_percent = similarities * 100

        return similarities_percent.tolist()

    def filter_posts_by_similarity(self,
                                   query: str,
                                   posts: List[Dict[str, Any]],
                                   threshold: float = 85.0,
                                   embedding_field: str = 'embedding',
                                   similarity_field: str = 'similarity_score') -> Tuple[
        List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        –§–∏–ª—å—Ç—Ä–∞—Ü–∏—è —Å–æ–æ–±—â–µ–Ω–∏–π –ø–æ –∫–æ—Å–∏–Ω—É—Å–Ω–æ–º—É —Å—Ö–æ–¥—Å—Ç–≤—É —Å –∑–∞–ø—Ä–æ—Å–æ–º

        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            posts: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 85%)
            embedding_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–º
            similarity_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è score

        Returns:
            Tuple: (–≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å score, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
        """
        if not posts:
            return [], []

        # –í–µ–∫—Ç–æ—Ä–∏–∑—É–µ–º –∑–∞–ø—Ä–æ—Å
        query_data = self.embed_query_sync(query)
        query_embedding = query_data['query_embedding']

        if not query_embedding:
            print("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —ç–º–±–µ–¥–¥–∏–Ω–≥ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞")
            return [], []

        # –°–æ–±–∏—Ä–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ —Å–æ–æ–±—â–µ–Ω–∏–π
        post_embeddings = []
        valid_posts = []

        for post in posts:
            if embedding_field in post and post[embedding_field] is not None:
                post_embeddings.append(post[embedding_field])
                valid_posts.append(post)

        if not post_embeddings:
            print("‚ö†Ô∏è –ù–µ—Ç –≤–∞–ª–∏–¥–Ω—ã—Ö —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –≤ —Å–æ–æ–±—â–µ–Ω–∏—è—Ö")
            return [], []

        # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
        similarities = self.calculate_cosine_similarity(query_embedding, post_embeddings)

        # –î–æ–±–∞–≤–ª—è–µ–º score –∫ —Å–æ–æ–±—â–µ–Ω–∏—è–º
        all_posts_with_scores = []
        filtered_posts = []

        for i, (post, similarity) in enumerate(zip(valid_posts, similarities)):
            # –°–æ–∑–¥–∞–µ–º –∫–æ–ø–∏—é –ø–æ—Å—Ç–∞, —á—Ç–æ–±—ã –Ω–µ –º–µ–Ω—è—Ç—å –æ—Ä–∏–≥–∏–Ω–∞–ª
            post_with_score = post.copy()
            post_with_score[similarity_field] = similarity
            post_with_score['query'] = query  # –î–æ–±–∞–≤–ª—è–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞

            all_posts_with_scores.append(post_with_score)

            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥
            if similarity >= threshold:
                filtered_posts.append(post_with_score)

        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Å—Ö–æ–¥—Å—Ç–≤–∞
        all_posts_with_scores.sort(key=lambda x: x[similarity_field], reverse=True)
        filtered_posts.sort(key=lambda x: x[similarity_field], reverse=True)

        print(f"üìä –í—Å–µ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {len(all_posts_with_scores)}")
        print(f"‚úÖ –°–æ–æ–±—â–µ–Ω–∏–π –≤—ã—à–µ –ø–æ—Ä–æ–≥–∞ {threshold}%: {len(filtered_posts)}")

        if filtered_posts:
            print(f"üìà –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ: {filtered_posts[0][similarity_field]:.2f}%")
            print(f"üìâ –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ —Å—Ä–µ–¥–∏ –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã—Ö: {filtered_posts[-1][similarity_field]:.2f}%")

        return all_posts_with_scores, filtered_posts

    def save_similarity_results(self,
                                all_posts: List[Dict[str, Any]],
                                filtered_posts: List[Dict[str, Any]],
                                query: str,
                                base_filename: str = "similarity_results",
                                output_dir: str = "results") -> Tuple[str, str]:
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å—á–µ—Ç–∞ —Å—Ö–æ–¥—Å—Ç–≤–∞ –≤ —Ñ–∞–π–ª—ã

        Args:
            all_posts: –í—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å score
            filtered_posts: –û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è
            query: –ò—Å—Ö–æ–¥–Ω—ã–π –∑–∞–ø—Ä–æ—Å
            base_filename: –ë–∞–∑–æ–≤–æ–µ –∏–º—è —Ñ–∞–π–ª–∞
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è

        Returns:
            Tuple: –ü—É—Ç–∏ –∫ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–º —Ñ–∞–π–ª–∞–º
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é, –µ—Å–ª–∏ –µ–µ –Ω–µ—Ç
        os.makedirs(output_dir, exist_ok=True)

        # –°–æ–∑–¥–∞–µ–º timestamp –¥–ª—è —É–Ω–∏–∫–∞–ª—å–Ω–æ—Å—Ç–∏ –∏–º–µ–Ω —Ñ–∞–π–ª–æ–≤
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è
        query_safe = query.replace(" ", "_").replace("/", "_")[:50]

        # 1. –§–∞–π–ª —Å–æ –≤—Å–µ–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏ –∏ score
        all_posts_filename = f"{base_filename}_all_{timestamp}_{query_safe}.json"
        all_posts_path = os.path.join(output_dir, all_posts_filename)

        all_results_data = {
            'query': query,
            'total_posts': len(all_posts),
            'timestamp': datetime.now().isoformat(),
            'posts': all_posts
        }

        with open(all_posts_path, 'w', encoding='utf-8') as f:
            json.dump(all_results_data, f, ensure_ascii=False, indent=2)

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å score: {all_posts_path}")

        # 2. –§–∞–π–ª —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏
        filtered_posts_filename = f"{base_filename}_filtered_{timestamp}_{query_safe}.json"
        filtered_posts_path = os.path.join(output_dir, filtered_posts_filename)

        filtered_results_data = {
            'query': query,
            'total_posts': len(filtered_posts),
            'timestamp': datetime.now().isoformat(),
            'posts': filtered_posts
        }

        with open(filtered_posts_path, 'w', encoding='utf-8') as f:
            json.dump(filtered_results_data, f, ensure_ascii=False, indent=2)

        print(f"üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω—ã –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è: {filtered_posts_path}")

        # 3. –¢–∞–∫–∂–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º –≤ Excel (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ)
        try:
            import pandas as pd

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Excel
            all_df = pd.DataFrame(all_posts)
            all_excel_path = os.path.join(output_dir, f"{base_filename}_all_{timestamp}_{query_safe}.xlsx")
            all_df.to_excel(all_excel_path, index=False)
            print(f"üìä Excel —Å–æ –≤—Å–µ–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: {all_excel_path}")

            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –≤ Excel
            if filtered_posts:
                filtered_df = pd.DataFrame(filtered_posts)
                filtered_excel_path = os.path.join(output_dir,
                                                   f"{base_filename}_filtered_{timestamp}_{query_safe}.xlsx")
                filtered_df.to_excel(filtered_excel_path, index=False)
                print(f"üìä Excel —Å –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–æ–æ–±—â–µ–Ω–∏—è–º–∏: {filtered_excel_path}")

        except ImportError:
            print("‚ö†Ô∏è Pandas –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω, Excel —Ñ–∞–π–ª—ã –Ω–µ —Å–æ–∑–¥–∞–Ω—ã")

        return all_posts_path, filtered_posts_path

    def search_similar_posts(self,
                             query: str,
                             posts: List[Dict[str, Any]],
                             threshold: float = 85.0,
                             save_results: bool = True) -> Tuple[List[Dict[str, Any]], List[Dict[str, Any]]]:
        """
        –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å –ø–æ–∏—Å–∫–∞ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π

        Args:
            query: –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
            posts: –°–ø–∏—Å–æ–∫ —Å–æ–æ–±—â–µ–Ω–∏–π —Å —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
            threshold: –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞ –≤ –ø—Ä–æ—Ü–µ–Ω—Ç–∞—Ö
            save_results: –°–æ—Ö—Ä–∞–Ω—è—Ç—å –ª–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤ —Ñ–∞–π–ª—ã

        Returns:
            Tuple: (–≤—Å–µ —Å–æ–æ–±—â–µ–Ω–∏—è —Å score, –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
        """
        print(f"\nüîç –ü–æ–∏—Å–∫ –ø–æ—Ö–æ–∂–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{query}'")
        print(f"üìä –ü–æ—Ä–æ–≥ —Å—Ö–æ–¥—Å—Ç–≤–∞: {threshold}%")

        # –§–∏–ª—å—Ç—Ä—É–µ–º —Å–æ–æ–±—â–µ–Ω–∏—è –ø–æ —Å—Ö–æ–¥—Å—Ç–≤—É
        all_posts_with_scores, filtered_posts = self.filter_posts_by_similarity(
            query=query,
            posts=posts,
            threshold=threshold
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        if save_results and all_posts_with_scores:
            self.save_similarity_results(all_posts_with_scores, filtered_posts, query)

        return all_posts_with_scores, filtered_posts

    async def add_embeddings_to_posts(self, posts: List[Dict[str, Any]],
                                      text_field: str = 'text',
                                      embedding_field: str = 'embedding',
                                      batch_size: int = 10) -> List[Dict[str, Any]]:
        """
        –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤ –∫ –ø–æ—Å—Ç–∞–º

        Args:
            posts: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ—Å—Ç–∞–º–∏
            text_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è —Å —Ç–µ–∫—Å—Ç–æ–º
            embedding_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            List[Dict]: –ü–æ—Å—Ç—ã —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        """
        if not posts:
            return posts

        async def process_batch(batch_posts: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
            """–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –ø–æ—Å—Ç–æ–≤"""
            tasks = []
            valid_posts = []

            # –°–æ–±–∏—Ä–∞–µ–º –∑–∞–¥–∞—á–∏ –¥–ª—è –≤–∞–ª–∏–¥–Ω—ã—Ö –ø–æ—Å—Ç–æ–≤
            for post in batch_posts:
                if text_field in post and post[text_field] and len(post[text_field].strip()) > 0:
                    tasks.append(self.get_embedding(post[text_field]))
                    valid_posts.append(post)
                else:
                    post[embedding_field] = None

            if not tasks:
                return batch_posts

            # –ó–∞–ø—É—Å–∫–∞–µ–º –≤—Å–µ –∑–∞–¥–∞—á–∏ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
            embeddings = await asyncio.gather(*tasks, return_exceptions=True)

            # –î–æ–±–∞–≤–ª—è–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏ –∫ –≤–∞–ª–∏–¥–Ω—ã–º –ø–æ—Å—Ç–∞–º
            for i, (post, embedding) in enumerate(zip(valid_posts, embeddings)):
                if isinstance(embedding, Exception):
                    print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –¥–ª—è –ø–æ—Å—Ç–∞ {i}: {embedding}")
                    post[embedding_field] = None
                else:
                    post[embedding_field] = embedding

            return batch_posts

        # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø–æ—Å—Ç—ã –±–∞—Ç—á–∞–º–∏
        result_posts = []
        total_batches = (len(posts) + batch_size - 1) // batch_size

        for i in range(0, len(posts), batch_size):
            batch = posts[i:i + batch_size]
            batch_num = i // batch_size + 1
            print(f"üîÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ {batch_num}/{total_batches}")

            processed_batch = await process_batch(batch)
            result_posts.extend(processed_batch)

            # –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –º–µ–∂–¥—É –±–∞—Ç—á–∞–º–∏, —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç—ã API
            if i + batch_size < len(posts):
                await asyncio.sleep(1)

        print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(result_posts)} –ø–æ—Å—Ç–æ–≤")
        return result_posts

    def add_embeddings_sync(self, posts: List[Dict[str, Any]],
                            text_field: str = 'text',
                            embedding_field: str = 'embedding',
                            batch_size: int = 10) -> List[Dict[str, Any]]:
        """
        –°–∏–Ω—Ö—Ä–æ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è –¥–æ–±–∞–≤–ª–µ–Ω–∏—è —ç–º–±–µ–¥–¥–∏–Ω–≥–æ–≤

        Args:
            posts: –°–ø–∏—Å–æ–∫ —Å–ª–æ–≤–∞—Ä–µ–π —Å –ø–æ—Å—Ç–∞–º–∏
            text_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è —Å —Ç–µ–∫—Å—Ç–æ–º
            embedding_field: –ù–∞–∑–≤–∞–Ω–∏–µ –ø–æ–ª—è –¥–ª—è —ç–º–±–µ–¥–¥–∏–Ω–≥–∞
            batch_size: –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–π –æ–±—Ä–∞–±–æ—Ç–∫–∏

        Returns:
            List[Dict]: –ü–æ—Å—Ç—ã —Å –¥–æ–±–∞–≤–ª–µ–Ω–Ω—ã–º–∏ —ç–º–±–µ–¥–¥–∏–Ω–≥–∞–º–∏
        """
        try:
            loop = asyncio.get_event_loop()
            if loop.is_running():
                # –ï—Å–ª–∏ —É–∂–µ –µ—Å—Ç—å –∑–∞–ø—É—â–µ–Ω–Ω—ã–π loop, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—É—é –∑–∞–¥–∞—á—É
                import nest_asyncio
                nest_asyncio.apply()
                return loop.run_until_complete(
                    self.add_embeddings_to_posts(posts, text_field, embedding_field, batch_size)
                )
        except RuntimeError:
            pass

        # –ï—Å–ª–∏ –Ω–µ—Ç event loop –∏–ª–∏ –æ–Ω —É–∂–µ –∑–∞–ø—É—â–µ–Ω, —Å–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π
        return asyncio.run(
            self.add_embeddings_to_posts(posts, text_field, embedding_field, batch_size)
        )